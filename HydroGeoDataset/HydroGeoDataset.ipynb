{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n",
      "Extracting PRISM data.\n",
      "Mask shape: (1849, 1458)\n",
      "Base mask shape: (1849, 1458)\n",
      "PRISM keys: <KeysViewHDF5 ['metadata', 'ppt', 'tmax', 'tmin']>\n",
      "Range of available years: <KeysViewHDF5 ['1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']>\n",
      "Size of the original PRISM data (year 2000): (366, 1849, 1458)\n",
      "Extracting PRISM data for the year 2000.\n",
      "Time mask shape: (366, 225, 68), Data shape: (366, 225, 68)\n",
      "Size of the original PRISM data (year 2001): (365, 1849, 1458)\n",
      "Extracting PRISM data for the year 2001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min row number: 749, Max row number: 974, Min column number: 473, Max column number: 541\n",
      "Min row number: 749, Max row number: 974, Min column number: 473, Max column number: 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time mask shape: (365, 225, 68), Data shape: (365, 225, 68)\n",
      "Final PRISM data shape: (731, 225, 68), (731, 225, 68), (731, 225, 68)\n",
      "Aggregated data shape (annual): (2, 225, 68), (2, 225, 68), (2, 225, 68)\n",
      "Aggregated data shape: (2, 225, 68), (2, 225, 68), (2, 225, 68)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################Aggregation method: annual#################\n"
     ]
    }
   ],
   "source": [
    "############################  example of loading PRISM data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling PRISM is nearest neighbor and have done with Arcpy. Note thate resampling of PRISM happened beforer H5 creation\n",
    "## PRISM data is in mm/day, C, C\n",
    "\n",
    "config = { \n",
    "    \"RESOLUTION\": 250,  ## resolution of the PRISM data\n",
    "    \"huc8\": None,\n",
    "    \"video\": False, ## if True, it will show the video of the PRISM data\n",
    "    \"aggregation\": \"annual\", ## aggregation of the PRISM data can be daily, monthly, yearly\n",
    "    \"start_year\": 2000,\n",
    "    \"end_year\": 2001,\n",
    "    'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "}\n",
    "importer = DataImporter(config)\n",
    "############################## example of loading PRISM data ###################################\n",
    "pr_prism, tmax_prism, tmin_prism = importer.PRISM() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n",
      "Mask shape: (1849, 1458)\n",
      "Attempting to load climate data for ACCESS-CM2, historical, r2i1p1f1, daily, 1950_2014.\n",
      "Size of the climate data: (731, 67, 75), (731, 67, 75), (731, 67, 75)\n",
      "Replication factors: (28, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1849, cols: 1458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size of the climate data after replication: (731, 1876, 1500), (731, 1876, 1500), (731, 1876, 1500)\n",
      "Flipping completed.\n",
      "Shape before cropping: (731, 1876, 1500), (731, 1876, 1500), (731, 1876, 1500)\n",
      "Size of the climate data after cropping: (731, 1849, 1458), (731, 1849, 1458), (731, 1849, 1458)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################Aggregation method: monthly#################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated data shape (monthly): (24, 1849, 1458), (24, 1849, 1458), (24, 1849, 1458)\n",
      "Aggregated data shape: (24, 1849, 1458), (24, 1849, 1458), (24, 1849, 1458)\n"
     ]
    }
   ],
   "source": [
    "####################### example of loading LOCA2 data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling LOCA2 is nearest neighbor and have done with numpy opeations. Note that the resampling of LOCA2 happens in HydroGeoDataset.py\n",
    "## NOTE: actual data unit in LOCA2 is kg m-2 s-1 for precipitation and K for temperature. We convert them to mm and C respectively in HydroGeoDataset.py\n",
    "\n",
    "config = {\n",
    "        \"RESOLUTION\": 250,\n",
    "        \"huc8\": None,\n",
    "        \"video\": False,\n",
    "        \"aggregation\": \"monthly\",\n",
    "        'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "    }\n",
    "\n",
    "importer = DataImporter(config)\n",
    "### NOTE: the list of all models and their ensemble is in /data/LOCA2/list_of_all_models.txt\n",
    "start_year = 2000\n",
    "end_year = 2001\n",
    "cc_model = \"ACCESS-CM2\"\n",
    "scenario = \"historical\"\n",
    "ensemble = \"r2i1p1f1\"\n",
    "\n",
    "ppt_loca2, tmax_loca2, tmin_loca2 = importer.LOCA2(start_year=start_year, end_year=end_year, cc_model= cc_model, scenario=scenario, ensemble=ensemble, cc_time_step='daily')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the HDF5 file: /data/SWATGenXApp/GenXAppData/HydroGeoDataset/HydroGeoDataset_ML_250.h5\n",
      "Total number of datasets: 276\n",
      "Extracting dataset: MODIS_ET_2001-01-01_to_2001-01-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-02-01_to_2001-02-28_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-03-01_to_2001-03-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-04-01_to_2001-04-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-05-01_to_2001-05-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-06-01_to_2001-06-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-07-01_to_2001-07-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-08-01_to_2001-08-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-09-01_to_2001-09-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-10-01_to_2001-10-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-11-01_to_2001-11-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-12-01_to_2001-12-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-01-01_to_2002-01-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-02-01_to_2002-02-28_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-03-01_to_2002-03-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-04-01_to_2002-04-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-05-01_to_2002-05-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-06-01_to_2002-06-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-07-01_to_2002-07-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-08-01_to_2002-08-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-09-01_to_2002-09-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-10-01_to_2002-10-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-11-01_to_2002-11-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-12-01_to_2002-12-31_006_250m\n",
      "Total number of datasets extracted: 24\n",
      "Shape of the extracted data: (24, 1849, 1458)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "from core import DataImporter\n",
    "\n",
    "### get MODIS Evapotranspiration data\n",
    "config = {\n",
    "    \"RESOLUTION\": 250,\n",
    "    \"huc8\": None,\n",
    "    \"video\": False,\n",
    "}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "start_year = 2000\n",
    "end_year = 2002\n",
    "et_modis = importer.MODIS_ET(start_year=start_year, end_year=end_year,  h5_group_name=\"MODIS/MODIS_ET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\"huc8\": \"4060105\",\n",
    "\t\t\"video\": True,\n",
    "\t}\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_3d_ds = importer.gw_3d_ds(start_year=2020, end_year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\n",
    "\t\t\"geospatial\": True,\n",
    "\t}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_station_data = importer.gw_stations_ds(start_year=1990, end_year=2021)\n",
    "\n",
    "print(f\"numerical feature: {gw_station_data['421332085401901_1609_389']['numerical_feature']}\")\n",
    "print(f\"categorical feature: {gw_station_data['421332085401901_1609_389']['categorical_feature']}\")\n",
    "print(f\"head: {gw_station_data['421332085401901_1609_389']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250,\n",
    "\t\"PFAS\": \"PFOS\"}   ### othr PFAS: PFHxS, PFOA, PFNA, PFDA, PFOS\n",
    "importer = DataImporter(config)\n",
    "\n",
    "pfas_max, pfas_mean, pfas_std = importer.import_pfas_data()\n",
    "\n",
    "print(f\"pfas_max: {pfas_max}\")\n",
    "print(f\"pfas_mean: {pfas_mean}\")\n",
    "print(f\"pfas_std: {pfas_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "extract_point_data = False\n",
    "if extract_point_data:\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\n",
    "\tinput_path = \"/data2/MyDataBase/HuronRiverPFAS/Huron_Biosolid_sites.geojson\"\n",
    "\toutput_path = \"/data/MyDataBase/test.pkl\"\n",
    "\timporter = DataImporter(config)\n",
    "\tgdf = importer.extract_features(input_path)\n",
    "\tgdf.to_pickle(output_path)\n",
    "\tgdf.to_file(output_path.replace(\".pkl\", \".shp\"))\n",
    "\n",
    "single_location_extraction = True\n",
    "if single_location_extraction:\n",
    "\t### a random location within Michigan LP\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\timporter = DataImporter(config)\n",
    "\tlat, lon = 42.0, -84.0\n",
    "\tgdf = importer.extract_features(single_location=(lat, lon))\n",
    "\n",
    "\tprint(f\"Extracted features: {gdf.columns}\")\n",
    "\n",
    "# Plot the shapefile\n",
    "#gdf.plot()\n",
    "#plt.savefig(\"input_figs/P_locations_rasters_30m.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 13:18:50,612 - INFO - Extracting snow_layer_thickness data for the year 2015.\n",
      "2024-12-20 13:18:51,279 - INFO - Size of the SNOWDAS data: (365, 1849, 1458)\n",
      "2024-12-20 13:18:53,130 - INFO - Size of the SNOWDAS data after cropping: (365, 1849, 1458)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (365, 1849, 1458)\n"
     ]
    }
   ],
   "source": [
    "# import snowdas data\n",
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250\n",
    "    }  \n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "data = importer.extract_snowdas_data(snowdas_var='snow_layer_thickness', year = 2015)  #'melt_rate', 'snow_accumulation', 'snow_layer_thickness', 'snow_water_equivalent', 'snowpack_sublimation_rate'. data range from 2004 to 2019\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the data for a specific location without using the DataImporter class\n",
    "from HydroGeoDataset.core import get_rowcol_index_by_latlon, get_rowcol_range_by_latlon, read_h5_file, hydrogeo_dataset_dict\n",
    "import h5py \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    path = \"/data/MyDataBase/HydroGeoDataset_ML_250.h5\"\n",
    "\n",
    "    dic = hydrogeo_dataset_dict()\n",
    "\n",
    "    print(dic['geospatial'])    \n",
    "    time.sleep(10)  \n",
    "    hydrogeo_dic = hydrogeo_dataset_dict(path)\n",
    "\n",
    "    lat, lon = 42.0, -84.0\n",
    "    row, col = get_rowcol_index_by_latlon(lat, lon, 250)\n",
    "    for key in hydrogeo_dic['geospatial']:\n",
    "        if key in [\"x_250m\", \"y_250m\", \"lat_250m\", \"lon_250m\", \"mask_250m\"]:\n",
    "            continue\n",
    "        address = f\"geospatial/{key}\"\n",
    "\n",
    "        data = read_h5_file(lat=row, lon=col, address=address)\n",
    "        print(f\"key: {key}, data: {data:.2f}\")\n",
    "\n",
    "\n",
    "        min_lat, max_lat = 41.5, 42.5\n",
    "        min_lon, max_lon = -84.5, -83.5\n",
    "        min_row_number, max_row_number, min_col_number, max_col_number = get_rowcol_range_by_latlon(min_lat, max_lat, min_lon, max_lon)\n",
    "        data = read_h5_file(address, lat_range=[min_row_number, max_row_number], lon_range=[min_col_number, max_col_number])\n",
    "        print(f\"key: {key}, average data: {data.mean():.2f}, median data: {np.median(data):.2f}, std data: {data.std():.2f}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
