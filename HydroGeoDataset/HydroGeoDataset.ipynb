{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################  example of loading PRISM data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling PRISM is nearest neighbor and have done with Arcpy. Note thate resampling of PRISM happened beforer H5 creation\n",
    "## PRISM data is in mm/day, C, C\n",
    "\n",
    "config = { \n",
    "    \"RESOLUTION\": 250,  ## resolution of the PRISM data\n",
    "    \"huc8\": None,\n",
    "    \"video\": False, ## if True, it will show the video of the PRISM data\n",
    "    \"aggregation\": \"annual\", ## aggregation of the PRISM data can be daily, monthly, yearly\n",
    "    \"start_year\": 2000,\n",
    "    \"end_year\": 2001,\n",
    "    'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "}\n",
    "importer = DataImporter(config)\n",
    "############################## example of loading PRISM data ###################################\n",
    "pr_prism, tmax_prism, tmin_prism = importer.PRISM() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### example of loading LOCA2 data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling LOCA2 is nearest neighbor and have done with numpy opeations. Note that the resampling of LOCA2 happens in HydroGeoDataset.py\n",
    "## NOTE: actual data unit in LOCA2 is kg m-2 s-1 for precipitation and K for temperature. We convert them to mm and C respectively in HydroGeoDataset.py\n",
    "\n",
    "config = {\n",
    "        \"RESOLUTION\": 250,\n",
    "        \"huc8\": None,\n",
    "        \"video\": False,\n",
    "        \"aggregation\": \"monthly\",\n",
    "        'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "    }\n",
    "\n",
    "importer = DataImporter(config)\n",
    "### NOTE: the list of all models and their ensemble is in /data/LOCA2/list_of_all_models.txt\n",
    "start_year = 2000\n",
    "end_year = 2001\n",
    "cc_model = \"ACCESS-CM2\"\n",
    "scenario = \"historical\"\n",
    "ensemble = \"r2i1p1f1\"\n",
    "\n",
    "ppt_loca2, tmax_loca2, tmin_loca2 = importer.LOCA2(start_year=start_year, end_year=end_year, cc_model= cc_model, scenario=scenario, ensemble=ensemble, cc_time_step='daily')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from core import DataImporter\n",
    "\n",
    "### get MODIS Evapotranspiration data\n",
    "config = {\n",
    "    \"RESOLUTION\": 250,\n",
    "    \"huc8\": None,\n",
    "    \"video\": False,\n",
    "}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "start_year = 2000\n",
    "end_year = 2002\n",
    "et_modis = importer.MODIS_ET(start_year=start_year, end_year=end_year,  h5_group_name=\"MODIS/MODIS_ET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\"huc8\": \"4060105\",\n",
    "\t\t\"video\": True,\n",
    "\t}\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_3d_ds = importer.gw_3d_ds(start_year=2020, end_year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\n",
    "\t\t\"geospatial\": True,\n",
    "\t}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_station_data = importer.gw_stations_ds(start_year=1990, end_year=2021)\n",
    "\n",
    "print(f\"numerical feature: {gw_station_data['421332085401901_1609_389']['numerical_feature']}\")\n",
    "print(f\"categorical feature: {gw_station_data['421332085401901_1609_389']['categorical_feature']}\")\n",
    "print(f\"head: {gw_station_data['421332085401901_1609_389']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250,\n",
    "\t\"PFAS\": \"PFOS\"}   ### othr PFAS: PFHxS, PFOA, PFNA, PFDA, PFOS\n",
    "importer = DataImporter(config)\n",
    "\n",
    "pfas_max, pfas_mean, pfas_std = importer.import_pfas_data()\n",
    "\n",
    "print(f\"pfas_max: {pfas_max}\")\n",
    "print(f\"pfas_mean: {pfas_mean}\")\n",
    "print(f\"pfas_std: {pfas_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "extract_point_data = False\n",
    "if extract_point_data:\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\n",
    "\tinput_path = \"/data2/MyDataBase/HuronRiverPFAS/Huron_Biosolid_sites.geojson\"\n",
    "\toutput_path = \"/data/MyDataBase/test.pkl\"\n",
    "\timporter = DataImporter(config)\n",
    "\tgdf = importer.extract_features(input_path)\n",
    "\tgdf.to_pickle(output_path)\n",
    "\tgdf.to_file(output_path.replace(\".pkl\", \".shp\"))\n",
    "\n",
    "single_location_extraction = True\n",
    "if single_location_extraction:\n",
    "\t### a random location within Michigan LP\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\timporter = DataImporter(config)\n",
    "\tlat, lon = 42.0, -84.0\n",
    "\tgdf = importer.extract_features(single_location=(lat, lon))\n",
    "\n",
    "\tprint(f\"Extracted features: {gdf.columns}\")\n",
    "\n",
    "# Plot the shapefile\n",
    "#gdf.plot()\n",
    "#plt.savefig(\"input_figs/P_locations_rasters_30m.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import snowdas data\n",
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250\n",
    "    }  \n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "data = importer.extract_snowdas_data(snowdas_var='snow_layer_thickness', year = 2015)  #'melt_rate', 'snow_accumulation', 'snow_layer_thickness', 'snow_water_equivalent', 'snowpack_sublimation_rate'. data range from 2004 to 2019\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the data for a specific location without using the DataImporter class\n",
    "from HydroGeoDataset.core import get_rowcol_index_by_latlon, get_rowcol_range_by_latlon, read_h5_file, hydrogeo_dataset_dict\n",
    "import h5py \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    path = \"/data/MyDataBase/HydroGeoDataset_ML_250.h5\"\n",
    "\n",
    "    dic = hydrogeo_dataset_dict()\n",
    "\n",
    "    print(dic['geospatial'])    \n",
    "    time.sleep(10)  \n",
    "    hydrogeo_dic = hydrogeo_dataset_dict(path)\n",
    "\n",
    "    lat, lon = 42.0, -84.0\n",
    "    row, col = get_rowcol_index_by_latlon(lat, lon, 250)\n",
    "    for key in hydrogeo_dic['geospatial']:\n",
    "        if key in [\"x_250m\", \"y_250m\", \"lat_250m\", \"lon_250m\", \"mask_250m\"]:\n",
    "            continue\n",
    "        address = f\"geospatial/{key}\"\n",
    "\n",
    "        data = read_h5_file(lat=row, lon=col, address=address)\n",
    "        print(f\"key: {key}, data: {data:.2f}\")\n",
    "\n",
    "\n",
    "        min_lat, max_lat = 41.5, 42.5\n",
    "        min_lon, max_lon = -84.5, -83.5\n",
    "        min_row_number, max_row_number, min_col_number, max_col_number = get_rowcol_range_by_latlon(min_lat, max_lat, min_lon, max_lon)\n",
    "        data = read_h5_file(address, lat_range=[min_row_number, max_row_number], lon_range=[min_col_number, max_col_number])\n",
    "        print(f\"key: {key}, average data: {data.mean():.2f}, median data: {np.median(data):.2f}, std data: {data.std():.2f}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
