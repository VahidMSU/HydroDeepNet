{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n",
      "Extracting PRISM data.\n",
      "Mask shape: (1849, 1458)\n",
      "Base mask shape: (1849, 1458)\n",
      "PRISM keys: <KeysViewHDF5 ['metadata', 'ppt', 'tmax', 'tmin']>\n",
      "Range of available years: <KeysViewHDF5 ['1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']>\n",
      "Size of the original PRISM data (year 2000): (366, 1849, 1458)\n",
      "Extracting PRISM data for the year 2000.\n",
      "Time mask shape: (366, 225, 68), Data shape: (366, 225, 68)\n",
      "Size of the original PRISM data (year 2001): (365, 1849, 1458)\n",
      "Extracting PRISM data for the year 2001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min row number: 749, Max row number: 974, Min column number: 473, Max column number: 541\n",
      "Min row number: 749, Max row number: 974, Min column number: 473, Max column number: 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time mask shape: (365, 225, 68), Data shape: (365, 225, 68)\n",
      "Final PRISM data shape: (731, 225, 68), (731, 225, 68), (731, 225, 68)\n",
      "Aggregated data shape (annual): (2, 225, 68), (2, 225, 68), (2, 225, 68)\n",
      "Aggregated data shape: (2, 225, 68), (2, 225, 68), (2, 225, 68)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################Aggregation method: annual#################\n"
     ]
    }
   ],
   "source": [
    "############################  example of loading PRISM data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling PRISM is nearest neighbor and have done with Arcpy. Note thate resampling of PRISM happened beforer H5 creation\n",
    "## PRISM data is in mm/day, C, C\n",
    "\n",
    "config = { \n",
    "    \"RESOLUTION\": 250,  ## resolution of the PRISM data\n",
    "    \"huc8\": None,\n",
    "    \"video\": False, ## if True, it will show the video of the PRISM data\n",
    "    \"aggregation\": \"annual\", ## aggregation of the PRISM data can be daily, monthly, yearly\n",
    "    \"start_year\": 2000,\n",
    "    \"end_year\": 2001,\n",
    "    'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "}\n",
    "importer = DataImporter(config)\n",
    "############################## example of loading PRISM data ###################################\n",
    "pr_prism, tmax_prism, tmin_prism = importer.PRISM() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/data/SWATGenXApp/LOCA2_MLP.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m scenario \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2i1p1f1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m ppt_loca2, tmax_loca2, tmin_loca2 \u001b[38;5;241m=\u001b[39m \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLOCA2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcc_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcc_time_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/SWATGenXApp/codes/HydroGeoDataset/core.py:743\u001b[0m, in \u001b[0;36mDataImporter.LOCA2\u001b[0;34m(self, start_year, end_year, cc_model, scenario, ensemble, cc_time_step, row, col)\u001b[0m\n\u001b[1;32m    740\u001b[0m start, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loca2_time_index_of_year(start_year, end_year)\n\u001b[1;32m    742\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/SWATGenXApp/LOCA2_MLP.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 743\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    744\u001b[0m \t\u001b[38;5;66;03m#self.logger.info(f\"LOCA2 keys: {f.keys()}\")\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \t\u001b[38;5;66;03m## time length \u001b[39;00m\n\u001b[1;32m    746\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mask()\n\u001b[1;32m    747\u001b[0m \t\u001b[38;5;66;03m#self.logger.info(f\"LOCA2 time length: {f['e_n_cent/ACCESS-CM2/historical/r1i1p1f1/daily/1950_2014/pr'].shape[0]}\")\u001b[39;00m\n",
      "File \u001b[0;32m/data/SWATGenXApp/codes/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/data/SWATGenXApp/codes/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/data/SWATGenXApp/LOCA2_MLP.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "####################### example of loading LOCA2 data ###################################\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from core import DataImporter\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "## NOTE: method for downscaling LOCA2 is nearest neighbor and have done with numpy opeations. Note that the resampling of LOCA2 happens in HydroGeoDataset.py\n",
    "## NOTE: actual data unit in LOCA2 is kg m-2 s-1 for precipitation and K for temperature. We convert them to mm and C respectively in HydroGeoDataset.py\n",
    "\n",
    "config = {\n",
    "        \"RESOLUTION\": 250,\n",
    "        \"huc8\": None,\n",
    "        \"video\": False,\n",
    "        \"aggregation\": \"monthly\",\n",
    "        'bounding_box': [-85.444332, 43.658148, -85.239256, 44.164683], # min_longitude, min_latitude, max_longitude, max_latitude\n",
    "    }\n",
    "\n",
    "importer = DataImporter(config)\n",
    "### NOTE: the list of all models and their ensemble is in /data/LOCA2/list_of_all_models.txt\n",
    "start_year = 2000\n",
    "end_year = 2001\n",
    "cc_model = \"ACCESS-CM2\"\n",
    "scenario = \"historical\"\n",
    "ensemble = \"r2i1p1f1\"\n",
    "\n",
    "ppt_loca2, tmax_loca2, tmin_loca2 = importer.LOCA2(start_year=start_year, end_year=end_year, cc_model= cc_model, scenario=scenario, ensemble=ensemble, cc_time_step='daily')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to /data/SWATGenXApp/codes/HydroGeoDataset/HydroGeoDataset.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the HDF5 file: /data/SWATGenXApp/GenXAppData/HydroGeoDataset/HydroGeoDataset_ML_250.h5\n",
      "Total number of datasets: 276\n",
      "Extracting dataset: MODIS_ET_2001-01-01_to_2001-01-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-02-01_to_2001-02-28_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-03-01_to_2001-03-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-04-01_to_2001-04-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-05-01_to_2001-05-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-06-01_to_2001-06-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-07-01_to_2001-07-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-08-01_to_2001-08-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-09-01_to_2001-09-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-10-01_to_2001-10-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-11-01_to_2001-11-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2001-12-01_to_2001-12-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-01-01_to_2002-01-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-02-01_to_2002-02-28_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-03-01_to_2002-03-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-04-01_to_2002-04-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-05-01_to_2002-05-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-06-01_to_2002-06-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-07-01_to_2002-07-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-08-01_to_2002-08-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-09-01_to_2002-09-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-10-01_to_2002-10-31_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-11-01_to_2002-11-30_006_250m\n",
      "Extracting dataset: MODIS_ET_2002-12-01_to_2002-12-31_006_250m\n",
      "Total number of datasets extracted: 24\n",
      "Shape of the extracted data: (24, 1849, 1458)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "from core import DataImporter\n",
    "\n",
    "### get MODIS Evapotranspiration data\n",
    "config = {\n",
    "    \"RESOLUTION\": 250,\n",
    "    \"huc8\": None,\n",
    "    \"video\": False,\n",
    "}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "start_year = 2000\n",
    "end_year = 2002\n",
    "et_modis = importer.MODIS_ET(start_year=start_year, end_year=end_year,  h5_group_name=\"MODIS/MODIS_ET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\"huc8\": \"4060105\",\n",
    "\t\t\"video\": True,\n",
    "\t}\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_3d_ds = importer.gw_3d_ds(start_year=2020, end_year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "config = {\n",
    "\t\t\"RESOLUTION\": 250,\n",
    "\t\t\n",
    "\t\t\"geospatial\": True,\n",
    "\t}\n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "gw_station_data = importer.gw_stations_ds(start_year=1990, end_year=2021)\n",
    "\n",
    "print(f\"numerical feature: {gw_station_data['421332085401901_1609_389']['numerical_feature']}\")\n",
    "print(f\"categorical feature: {gw_station_data['421332085401901_1609_389']['categorical_feature']}\")\n",
    "print(f\"head: {gw_station_data['421332085401901_1609_389']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250,\n",
    "\t\"PFAS\": \"PFOS\"}   ### othr PFAS: PFHxS, PFOA, PFNA, PFDA, PFOS\n",
    "importer = DataImporter(config)\n",
    "\n",
    "pfas_max, pfas_mean, pfas_std = importer.import_pfas_data()\n",
    "\n",
    "print(f\"pfas_max: {pfas_max}\")\n",
    "print(f\"pfas_mean: {pfas_mean}\")\n",
    "print(f\"pfas_std: {pfas_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "\n",
    "extract_point_data = False\n",
    "if extract_point_data:\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\n",
    "\tinput_path = \"/data2/MyDataBase/HuronRiverPFAS/Huron_Biosolid_sites.geojson\"\n",
    "\toutput_path = \"/data/MyDataBase/test.pkl\"\n",
    "\timporter = DataImporter(config)\n",
    "\tgdf = importer.extract_features(input_path)\n",
    "\tgdf.to_pickle(output_path)\n",
    "\tgdf.to_file(output_path.replace(\".pkl\", \".shp\"))\n",
    "\n",
    "single_location_extraction = True\n",
    "if single_location_extraction:\n",
    "\t### a random location within Michigan LP\n",
    "\tconfig = {\n",
    "\t\t\"RESOLUTION\": 250}\n",
    "\timporter = DataImporter(config)\n",
    "\tlat, lon = 42.0, -84.0\n",
    "\tgdf = importer.extract_features(single_location=(lat, lon))\n",
    "\n",
    "\tprint(f\"Extracted features: {gdf.columns}\")\n",
    "\n",
    "# Plot the shapefile\n",
    "#gdf.plot()\n",
    "#plt.savefig(\"input_figs/P_locations_rasters_30m.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 13:18:50,612 - INFO - Extracting snow_layer_thickness data for the year 2015.\n",
      "2024-12-20 13:18:51,279 - INFO - Size of the SNOWDAS data: (365, 1849, 1458)\n",
      "2024-12-20 13:18:53,130 - INFO - Size of the SNOWDAS data after cropping: (365, 1849, 1458)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (365, 1849, 1458)\n"
     ]
    }
   ],
   "source": [
    "# import snowdas data\n",
    "\n",
    "import sys \n",
    "sys.path.append('/data/SWATGenXApp/codes/HydroGeoDataset')\n",
    "from HydroGeoDataset.core import DataImporter\n",
    "config = {\n",
    "\t\"RESOLUTION\": 250\n",
    "    }  \n",
    "\n",
    "importer = DataImporter(config)\n",
    "\n",
    "data = importer.extract_snowdas_data(snowdas_var='snow_layer_thickness', year = 2015)  #'melt_rate', 'snow_accumulation', 'snow_layer_thickness', 'snow_water_equivalent', 'snowpack_sublimation_rate'. data range from 2004 to 2019\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the data for a specific location without using the DataImporter class\n",
    "from HydroGeoDataset.core import get_rowcol_index_by_latlon, get_rowcol_range_by_latlon, read_h5_file, hydrogeo_dataset_dict\n",
    "import h5py \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    path = \"/data/MyDataBase/HydroGeoDataset_ML_250.h5\"\n",
    "\n",
    "    dic = hydrogeo_dataset_dict()\n",
    "\n",
    "    print(dic['geospatial'])    \n",
    "    time.sleep(10)  \n",
    "    hydrogeo_dic = hydrogeo_dataset_dict(path)\n",
    "\n",
    "    lat, lon = 42.0, -84.0\n",
    "    row, col = get_rowcol_index_by_latlon(lat, lon, 250)\n",
    "    for key in hydrogeo_dic['geospatial']:\n",
    "        if key in [\"x_250m\", \"y_250m\", \"lat_250m\", \"lon_250m\", \"mask_250m\"]:\n",
    "            continue\n",
    "        address = f\"geospatial/{key}\"\n",
    "\n",
    "        data = read_h5_file(lat=row, lon=col, address=address)\n",
    "        print(f\"key: {key}, data: {data:.2f}\")\n",
    "\n",
    "\n",
    "        min_lat, max_lat = 41.5, 42.5\n",
    "        min_lon, max_lon = -84.5, -83.5\n",
    "        min_row_number, max_row_number, min_col_number, max_col_number = get_rowcol_range_by_latlon(min_lat, max_lat, min_lon, max_lon)\n",
    "        data = read_h5_file(address, lat_range=[min_row_number, max_row_number], lon_range=[min_col_number, max_col_number])\n",
    "        print(f\"key: {key}, average data: {data.mean():.2f}, median data: {np.median(data):.2f}, std data: {data.std():.2f}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
