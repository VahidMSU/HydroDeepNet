{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555451d2-30da-46be-9295-8af08bc17c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "from arcpy.ga import *\n",
    "from arcpy.management import Delete\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "import gc\n",
    "from shapely.geometry import box\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print('started')\n",
    "\n",
    "#\"\"\" the HCOND1 values in the water wells represent the \n",
    "#lithology of the screen intervals where the HCOND2 values represent the saturated thickness in \n",
    "#the water wells (or the saturated thickness of the glacial aquifer where the aquifer thickness is \n",
    "#small). \"\"\"\"\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "def calculate_rmse(predicted_values, known_values):\n",
    "    \"\"\"Calculate the root mean square error (RMSE) between predicted and known values.\"\"\"\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    known_values = np.array(known_values)\n",
    "    square_errors = (predicted_values - known_values) ** 2\n",
    "    mean_square_error = np.mean(square_errors)\n",
    "    rmse = np.sqrt(mean_square_error)\n",
    "    return rmse\n",
    "\n",
    "def plot_krigging_vs_data(shape_temp, parameter, COUNTY):\n",
    "    save_path = dic + fr'Fitness/{parameter}_{COUNTY}.png'\n",
    "    filtered_data = shape_temp[(shape_temp.RASTERVALU > 0) & (shape_temp.COUNTY == COUNTY)]\n",
    "    joint = sns.jointplot(x=filtered_data[parameter], y=filtered_data['RASTERVALU'], \n",
    "                          kind='scatter', joint_kws={\"s\": 5})\n",
    "    joint.ax_joint.set_xlabel(f'Original {parameter}')\n",
    "    joint.ax_joint.set_ylabel(f'Predicted {parameter}')\n",
    "    joint.fig.suptitle(f'{COUNTY}')\n",
    "    joint.ax_joint.grid(True, alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def create_mask(cs, COUNTY, buffer_distance, michigan_boundary_path):\n",
    "    mask = cs[cs.COUNTY == COUNTY].buffer(buffer_distance)\n",
    "    mask_extent = mask.geometry.total_bounds\n",
    "    shapefile_gdf = gpd.read_file(michigan_boundary_path)\n",
    "    mask_polygon = box(*mask_extent)\n",
    "    is_mask_within_shapefile = shapefile_gdf.geometry.contains(mask_polygon).any()\n",
    "    \n",
    "    if not is_mask_within_shapefile:\n",
    "        mask = gpd.clip(mask, shapefile_gdf)\n",
    "\n",
    "    return mask, mask_extent\n",
    "\n",
    "dic= r\"D:/GW_data_interpolated/Well_data_krigging/\"  #### base directory\n",
    "#,,'SWL','H_COND_2','V_COND_1', 'V_COND_2', 'TRANSMSV_1', \n",
    "parameters = ['TRANSMSV_2','TRANSMSV_1','AQ_THK_1', 'AQ_THK_2' ,'SWL', 'V_COND_1', 'V_COND_2','H_COND_2','H_COND_1']       \n",
    "#groundwater_data_path=dic+r\"WaterWells_Michigan_combined_projected_gr.pk1\"\n",
    "\n",
    "groundwater_data_path='D:/GW_data_interpolated/Grid/grid_points_well_obs_with_geometry.pk1'\n",
    "\n",
    "counties_data_path=dic+'Counties_dis_gr.pk1'\n",
    "michigan_boundary_path=dic+r\"MichiganBoundry_26990.shp\"\n",
    "crs_setting='EPSG:26990'\n",
    "#### cleaning and cover range\n",
    "maximum_observed_head_allowed=520\n",
    "buffer_distance_for_county = 5000\n",
    "\n",
    "##### krigging parameters for optimization\n",
    "\n",
    "STK=False\n",
    "EBK=True\n",
    "\n",
    "if EBK==True:\n",
    "    print('EBK algorithm will be used')\n",
    "    max_local_points_values = range(50, 256)\n",
    "    overlap_factor_values = [x * 0.1 for x in range(10, 30)]  # this will generate values from 1.0 to 3.0 with a step of 0.1\n",
    "    number_semivariograms_values = [50, 100, 200, 300]\n",
    "    cell_size_values = [250]\n",
    "    transformation_type_values = [\"EMPIRICAL\"]\n",
    "    semivariogram_model_type_values = [\"EXPONENTIAL\", \"EXPONENTIAL_DETRENDED\", \"WHITTLE\", \"WHITTLE_DETRENDED\", \"K_BESSEL\", 'K_BESSEL_DETRENDED']\n",
    "\n",
    "elif STK==True:\n",
    "    print('STK algorithm will be used')\n",
    "    semivariogram_model_type_values = [\"SPHERICAL\", \"CIRCULAR\", \"EXPONENTIAL\", \"GAUSSIAN\", \"LINEAR\"]\n",
    "    cell_size_values = [250]\n",
    "    nugget_values = [0, 0.5, 1.0]\n",
    "    range_values = [100, 200, 300]\n",
    "    lag_size_values = [5, 10, 15]\n",
    "    major_range_values = [50, 100, 150]\n",
    "    partial_sill_values = [10, 20, 30]\n",
    "    lag_number_values = [5, 10, 15]\n",
    "\n",
    "n_iterations = 10\n",
    "up_threshorld=0.975\n",
    "low_threshold=0.025\n",
    "\n",
    "for parameter in parameters:\n",
    "    GWD = gpd.GeoDataFrame(pd.read_pickle(groundwater_data_path), crs=crs_setting, geometry='geometry')\n",
    "    cs = gpd.GeoDataFrame(pd.read_pickle(counties_data_path), crs=crs_setting, geometry='geometry')\n",
    "    COUNTIES=sorted(GWD[~GWD.COUNTY.isna()].COUNTY.unique(), reverse=True)\n",
    "    \n",
    "    for COUNTY in COUNTIES:\n",
    "        print(parameter, COUNTY)\n",
    "        mask, mask_extent = create_mask(cs, COUNTY, buffer_distance_for_county, michigan_boundary_path)\n",
    "        arcpy.env.extent = arcpy.Extent(mask_extent[0], mask_extent[1], mask_extent[2], mask_extent[3])\n",
    "        path = dic+fr'Krigging_work_space/{parameter}_{COUNTY}'\n",
    "        GWD_cleaned=GWD[~GWD[parameter].isna()][['COUNTY',parameter,'geometry']].reset_index(drop=True)\n",
    "        GWD_cleaned=GWD_cleaned.clip(mask).reset_index(drop=True)\n",
    "        GWD_cleaned = GWD_cleaned.drop_duplicates(subset='geometry').reset_index(drop=True)\n",
    "        GWD_cleaned = GWD_cleaned[(GWD_cleaned[parameter] < GWD_cleaned[parameter].quantile(up_threshorld)) & (GWD_cleaned[parameter] > GWD_cleaned[parameter].quantile(low_threshold))].reset_index(drop=True)\n",
    "        #GWD_cleaned = GWD_cleaned[GWD_cleaned.SWL<maximum_observed_head_allowed].reset_index(drop=True)\n",
    "       \n",
    "        GWD_cleaned.to_file(path)\n",
    "        env.workspace = dic+r'Krigging_work_space'\n",
    "        in_features = f\"{parameter}_{COUNTY}/{parameter}_{COUNTY}.shp\"\n",
    "        z_field = parameter\n",
    "        out_surface_raster = f\"kriging_output_{parameter}_{COUNTY}.tif\" \n",
    "        arcpy.env.overwriteOutput = True\n",
    "        # Initialize variables for the best RMSE and parameters\n",
    "        best_rmse = float('inf')\n",
    "        best_params = None\n",
    "\n",
    "        for _ in range(n_iterations):\n",
    "            # Randomly select parameter values\n",
    "            if EBK==True:\n",
    "                cell_size = random.choice(cell_size_values)\n",
    "                transformation_type = random.choice(transformation_type_values)\n",
    "                max_local_points = random.choice(max_local_points_values)\n",
    "                overlap_factor = random.choice(overlap_factor_values)\n",
    "                number_semivariograms = random.choice(number_semivariograms_values)\n",
    "                semivariogram_model_type = random.choice(semivariogram_model_type_values)\n",
    "                \n",
    "            elif STK==True:\n",
    "                cell_size = random.choice(cell_size_values)\n",
    "                semivariogram_model_type = random.choice(semivariogram_model_type_values)\n",
    "                nugget = random.choice(nugget_values)\n",
    "                range_value = random.choice(range_values)\n",
    "                lag_size = random.choice(lag_size_values)\n",
    "                major_range = random.choice(major_range_values)\n",
    "                partial_sill = random.choice(partial_sill_values)\n",
    "                lag_number = random.choice(lag_number_values)\n",
    "                \n",
    "            out_ga_layer = \"\"\n",
    "            out_raster = out_surface_raster\n",
    "            output_type_values = [ \"PREDICTION_STANDARD_ERROR\",\"PREDICTION\"]\n",
    "    \n",
    "            for output_type in output_type_values:\n",
    "                if output_type == \"PREDICTION_STANDARD_ERROR\":\n",
    "                    out_raster_error = f\"kriging_stderr_{parameter}_{COUNTY}.tif\" \n",
    "                else:\n",
    "                    out_raster_pred = f\"kriging_output_{parameter}_{COUNTY}.tif\" \n",
    "                    out_raster_best_pred = f\"kriging_best_{parameter}_{COUNTY}.tif\" \n",
    "\n",
    "            # Execute Empirical Bayesian Kriging with current parameters\n",
    "            \n",
    "            if EBK==True:\n",
    "                arcpy.EmpiricalBayesianKriging_ga(in_features, z_field, out_ga_layer, out_raster_pred, cell_size, \n",
    "                                                  transformation_type, max_local_points, overlap_factor, \n",
    "                                                  number_semivariograms, \"\", 'PREDICTION', \"\", \"\", \"\", \n",
    "                                                  semivariogram_model_type)\n",
    "            elif STK==True:\n",
    "                kriging_model = KrigingModelOrdinary(semivariogram_model_type, lag_size, major_range, partial_sill, nugget)\n",
    "                outKriging = Kriging(in_features, z_field, kriging_model, cell_size, \"VARIABLE\", None)\n",
    "                outKriging.save(out_raster_pred)\n",
    "\n",
    "\n",
    "            tif_path = dic+fr'Krigging_work_space/kriging_output_{parameter}_{COUNTY}.tif'\n",
    "            shapefile_path = dic+fr'Krigging_work_space/{parameter}_{COUNTY}/{parameter}_{COUNTY}.shp'\n",
    "            arcpy.env.workspace = dic+fr'Krigging_work_space/'\n",
    "            arcpy.sa.ExtractValuesToPoints(shapefile_path, tif_path, \"calibration_temp.shp\", \"INTERPOLATE\", \"VALUE_ONLY\")\n",
    "            shape_temp=gpd.read_file(dic+\"Krigging_work_space/calibration_temp.shp\")\n",
    "            rmse=calculate_rmse(shape_temp[(shape_temp.RASTERVALU>0) & (shape_temp.COUNTY==COUNTY)][parameter].values, shape_temp[(shape_temp.RASTERVALU>0) & (shape_temp.COUNTY==COUNTY)].RASTERVALU.values )    \n",
    "            print('RMSE: ',rmse)\n",
    "            if rmse < best_rmse:\n",
    "                print('better solution foound')\n",
    "                if EBK==True:\n",
    "                    arcpy.EmpiricalBayesianKriging_ga(in_features, z_field, out_ga_layer, out_raster_error, cell_size, \n",
    "                                      transformation_type, max_local_points, overlap_factor, \n",
    "                                      number_semivariograms, \"\", \"PREDICTION_STANDARD_ERROR\", \"\", \"\", \"\", \n",
    "                                      semivariogram_model_type)\n",
    "\n",
    "                    arcpy.EmpiricalBayesianKriging_ga(in_features, z_field, out_ga_layer, out_raster_best_pred, cell_size, \n",
    "                                      transformation_type, max_local_points, overlap_factor, \n",
    "                                      number_semivariograms, \"\", 'PREDICTION', \"\", \"\", \"\", \n",
    "                                      semivariogram_model_type)  \n",
    "                    \n",
    "                    \n",
    "                best_rmse = rmse\n",
    "                plot_krigging_vs_data(shape_temp, parameter, COUNTY)\n",
    "            time.sleep(1)\n",
    "            gc.collect()\n",
    "        directory_path = dic+'Krigging_work_space'\n",
    "        for item in os.listdir(dic+'Krigging_work_space'):\n",
    "            item_path = os.path.join(directory_path, item)\n",
    "            if os.path.isdir(item_path) and item != 'clip':\n",
    "                shutil.rmtree(item_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816686b3-a1e3-49cb-bbe4-cfe40d2dc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "arcpy.env.overwriteOutput = True\n",
    "import shutil\n",
    "\n",
    "def masking_krigged_data(cs,input_rasters):\n",
    "    for raster in input_rasters:\n",
    "        # Extract county name from the raster file name\n",
    "        county_name = raster.split('\\\\')[-1].split(f'kriging_{typ}_')[1].split('.')[0].split(f'{parameter}_')[1]\n",
    "        # Get the polygon corresponding to the county\n",
    "        county_polygon = cs[cs.COUNTY==county_name].buffer(500)\n",
    "        # Save the county polygon to a temporary shapefile\n",
    "        county_polygon.to_file(county_name + '_temp.shp')\n",
    "        # Define the output raster file name\n",
    "        output_raster = raster.replace('.tif', '_masked.tif')\n",
    "        # Extract by mask\n",
    "        outExtractByMask = ExtractByMask(raster, county_name + '_temp.shp')\n",
    "        # Save the output \n",
    "        outExtractByMask.save(output_raster)\n",
    "\n",
    "def creating_mosaic_from_krigged_masked(cs,input_rasters,out_dic):\n",
    "    output_location = dic+'clip'\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    input_rasters = glob.glob(dic+fr'/kriging_{typ}_{parameter}_*masked.tif')\n",
    "    mosaic = arcpy.MosaicToNewRaster_management(input_rasters, output_location, f'{parameter}_{typ}_mosaic.tif', '', '64_BIT', '250', '1', 'BLEND')\n",
    "    mask_geometry = cs.geometry.unary_union\n",
    "    # Save the mask as a shapefile\n",
    "    mask_shp = gpd.GeoDataFrame(gpd.GeoSeries(mask_geometry), columns=['geometry'])\n",
    "    mask_shp.set_crs(epsg=26990, inplace=True)\n",
    "    mask_shp.to_file('mask.shp')\n",
    "    # Now use 'mask.shp' as the mask in the ExtractByMask function\n",
    "    outExtractByMask = ExtractByMask(mosaic, 'mask.shp')\n",
    "    output_raster = os.path.join(out_dic, f'{typ}_{parameter}.tif')\n",
    "    # Save the output \n",
    "    outExtractByMask.save(output_raster)\n",
    "\n",
    "typs=['best','stderr']\n",
    "dic=r'C:/Users/rafieiva/OneDrive - Michigan State University/Desktop/GW_data_interpolated/Well_data_krigging/Krigging_work_space/'\n",
    "out_dic=r'C:/Users/rafieiva/OneDrive - Michigan State University/Desktop/GW_data_interpolated/Well_data_krigging/Krigged_data/'\n",
    "parameters=['SWL', 'AQ_THK_1','AQ_THK_2','V_COND_2', 'V_COND_1','TRANSMSV_1','TRANSMSV_2','H_COND_1','H_COND_2']\n",
    "arcpy.env.workspace = dic\n",
    "\n",
    "for parameter in parameters:\n",
    "    for typ in typs:\n",
    "        file_list = glob.glob(os.path.join( dic+'clip', '*'))\n",
    "        for file_path in file_list:\n",
    "            os.remove(file_path)\n",
    "        print('Files in clip folder are deleted ')\n",
    "        mask_removal = glob.glob(dic+'*masked.tif')\n",
    "        for file in mask_removal:\n",
    "            os.remove(file)\n",
    "        print(' masked files in input folder have been deleted')\n",
    "        cs = gpd.GeoDataFrame(pd.read_pickle('Counties_dis_gr.pk1'), crs='EPSG:26990')\n",
    "        folder_path = os.path.join(dic, 'clip')\n",
    "\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        env.workspace = dic\n",
    "        arcpy.env.nodata = 'NONE'\n",
    "        input_rasters = glob.glob(dic+f'kriging_{typ}_{parameter}_*.tif')\n",
    "        masking_krigged_data(cs,input_rasters)\n",
    "        print('All rasters have been masked.')\n",
    "        creating_mosaic_from_krigged_masked(cs,input_rasters,out_dic)\n",
    "\n",
    "        if typ=='best':\n",
    "            if parameter in ['V_COND_1','V_COND_2','H_COND_1','H_COND_2']:\n",
    "                out_min = 0\n",
    "                out_max = 300 \n",
    "            elif parameter in ['TRANSMSV_1','TRANSMSV_2']:\n",
    "                out_min = 0.0004\n",
    "                out_max = 72100\n",
    "            elif parameter in ['AQ_THK_1','AQ_THK_2']:\n",
    "                out_min = 1\n",
    "                out_max = 478.0       \n",
    "            elif parameter in ['SWL']:\n",
    "                out_min = 0\n",
    "                out_max = 511\n",
    "            \n",
    "            temp_path=os.path.join(out_dic, fr'best_{parameter}.tif')\n",
    "            saved_raster = arcpy.Raster(temp_path)\n",
    "            neighborhood = NbrRectangle(3, 3, 'CELL') # You can adjust the size\n",
    "            smoothed_raster = FocalStatistics(saved_raster, neighborhood, 'MEAN')\n",
    "            temp_path=os.path.join(out_dic, fr'best_{parameter}_smoothed.tif')\n",
    "            smoothed_raster.save(temp_path)\n",
    "            print('smoothing compeleted')\n",
    "            temp_path=os.path.join(out_dic,fr'best_{parameter}_smoothed.tif')\n",
    "            smoothed_raster = arcpy.Raster(temp_path)\n",
    "            in_min = smoothed_raster.minimum\n",
    "            in_max = smoothed_raster.maximum\n",
    "            scale = (out_max - out_min) / (in_max - in_min)\n",
    "            base = out_min - in_min * scale\n",
    "            scaled_raster = smoothed_raster * scale + base\n",
    "            temp_path=os.path.join(out_dic, fr'best_{parameter}_smoothed_rescaled.tif')\n",
    "            scaled_raster.save(temp_path)\n",
    "            print('rescaling compeleted')\n",
    "        else:\n",
    "            temp_path=os.path.join(out_dic, fr'stderr_{parameter}.tif')\n",
    "            saved_raster = arcpy.Raster(temp_path)\n",
    "            neighborhood = NbrRectangle(3, 3, 'CELL') # You can adjust the size\n",
    "            smoothed_raster = FocalStatistics(saved_raster, neighborhood, 'MEAN')\n",
    "            # Save the output\n",
    "            temp_path=os.path.join(out_dic, fr'stderr_{parameter}_smoothed.tif')\n",
    "            smoothed_raster.save(temp_path)\n",
    "            print('smoothing compeleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee150a-58bf-4a08-b8a8-b44aba9c7a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "56def041-f622-4c04-9a32-10fef8bd5ab4",
   "metadata": {},
   "source": [
    "# Original dictionary\n",
    "cs = gpd.GeoDataFrame(pd.read_pickle('Counties_(v17a).pk1'), crs='EPSG:26990')\n",
    "# Original dictionary\n",
    "BASE_PATH={'G1':['Sanilac', 'Tuscola','Huron'],\n",
    "'G2':['Gladwin','Midland', 'Saginaw', 'Bay', 'Arenac'],\n",
    "'G3':['Clinton','Shiawassee','Eaton','Ingham','Livingston', 'Calhoun','Jackson', 'Washtenaw'],\n",
    "'G4':['Wayne', 'Monroe'],\n",
    "'G5':['Alpena', 'Presque_Isle']}\n",
    "\n",
    "# Reverse the dictionary\n",
    "reverse_dic = {county: group for group, counties in BASE_PATH.items() for county in counties}\n",
    "\n",
    "# Rename counties\n",
    "cs['COUNTY'] = cs['COUNTY'].replace(reverse_dic)\n",
    "\n",
    "cs=cs.dissolve('COUNTY')\n",
    "cs = cs.reset_index()\n",
    "cs.to_pickle('Counties_dis_gr.pk1')\n",
    "\n",
    "# Reverse the dictionary\n",
    "\n",
    "WHO = gpd.GeoDataFrame(pd.read_pickle('WaterWells_Michigan_combined_projected.pkl'), crs='EPSG:26990')\n",
    "reverse_dic = {county: group for group, counties in BASE_PATH.items() for county in counties}\n",
    "\n",
    "WHO['COUNTY'] = WHO['COUNTY'].replace(reverse_dic)\n",
    "\n",
    "WHO.to_pickle(\"E:\\Michigan Big Data\\SWATplus_by_VPUID\\WaterWells_Michigan_combined_projected_gr.pk1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
