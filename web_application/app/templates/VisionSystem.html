{% extends "layout.html" %} {% block title %}GeoCNN: Vision System Software{%
endblock %} {% block content %}
<style>
  /* Main Layout Styling */
  .row {
    display: flex;
    flex-wrap: nowrap; /* Ensure both columns are side-by-side */
    gap: 20px;
    align-items: stretch;
    height: calc(
      100vh - 50px
    ); /* Adjust for full-page height excluding header */
  }

  .col-half {
    flex: 1; /* Take equal width for both columns */
    min-width: 300px; /* Ensure it doesn't shrink too small */
    display: flex;
    flex-direction: column;
    justify-content: stretch;
    align-items: stretch;
  }

  /* Form Container Styling */
  .form-container {
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    padding: 20px;
    background-color: #ffffff;
    overflow-y: auto; /* Allow scrolling if form content is long */
  }

  .form-container h2 {
    font-size: 1.8rem;
    margin-bottom: 20px;
    text-align: center;
  }

  .form-group label {
    font-weight: bold;
    margin-bottom: 5px;
    display: block;
  }

  .form-control {
    border-radius: 5px;
    padding: 10px;
    font-size: 1rem;
  }

  button {
    border-radius: 5px;
  }
  /* Map Container Styling */
  #viewDiv {
    height: 700px !important; /* Set the desired height */
    width: 500%; /* Ensure width stays responsive */
    border: 1px solid #ccc;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  }

  /* Responsive Adjustments */
  @media (max-width: 768px) {
    #viewDiv {
      height: 400px; /* Slightly smaller height for smaller screens */
    }
  }
</style>

<div class="container mt-4">
  <h1 class="mb-4 text-center">Vision System Deep Learning</h1>

  <!-- Introduction & Showcasing Results -->
  <div class="card mb-4">
    <div class="card-body">
      <p class="lead">
        GeoCNN is a streamlined deep learning framework designed for
        hydrological modeling. It processes large-scale spatiotemporal
        data—integrating remote sensing, climate, and soil/land cover inputs—to
        predict monthly water balance components (e.g., ET) across the Michigan
        Lower Peninsula.
      </p>
      <div class="text-center mt-4">
        <img
          src="{{ url_for('static', filename='images/DeepLearningMichiganET_CNNTransformer.gif') }}"
          alt="GeoCNN Deep Learning GIF"
          class="img-fluid"
        />
      </div>
      <div class="text-center mt-4">
        <h5>Predictions vs. Ground Truth (Single Batches)</h5>
        <div class="d-flex flex-wrap justify-content-center gap-3">
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_1_0.gif') }}"
            alt="Batch 1 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_2_0.gif') }}"
            alt="Batch 2 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_3_0.gif') }}"
            alt="Batch 3 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_4_0.gif') }}"
            alt="Batch 4 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_5_0.gif') }}"
            alt="Batch 5 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
          <img
            src="{{ url_for('static', filename='images/predictions_vs_ground_truth_batch_6_0.gif') }}"
            alt="Batch 6 Predictions vs Ground Truth"
            class="img-fluid small-gif"
          />
        </div>
        <h5 class="mt-4">Cell-wise NSE Performance</h5>
        <img
          src="{{ url_for('static', filename='images/cell_wise_nse_performance.png') }}"
          alt="Cell-wise NSE Performance"
          class="img-fluid"
        />
      </div>
    </div>
  </div>

  <!-- Key Components & Overview -->
  <h2 class="mt-4">Overview of GeoCNN</h2>
  <div class="card mb-4">
    <div class="card-body">
      <p>GeoCNN efficiently handles:</p>
      <ul>
        <li>
          <strong>Large Datasets:</strong> Fast loading/reloading of multi-year
          monthly data.
        </li>
        <li>
          <strong>Multi-Scale Inputs:</strong> Incorporates MODIS, PRISM, soil,
          and land cover info.
        </li>
        <li>
          <strong>Powerful Architectures:</strong> CNN-Transformers and fully
          Transformer-based models.
        </li>
        <li>
          <strong>Spatial & Temporal Flexibility:</strong> Custom skip
          connections, attention, and advanced up/down-sampling.
        </li>
      </ul>
      <p>
        Target variables (e.g., ET) are observed at 250m resolution across
        Michigan. Data gaps are filled using water masks, mean interpolation,
        and global scaling from 0 to 1. Invalid areas (like Lake Michigan) are
        marked to help the model distinguish land vs. water.
      </p>
    </div>
  </div>

  <!-- Data Pipeline -->
  <h2 class="mt-4">Data Pipeline</h2>
  <div class="card mb-4">
    <div class="card-body">
      <p>
        GeoCNN’s data pipeline handles monthly raster stacks spanning 2001–2021.
        Temporal aggregation (summing precipitation, averaging temperature)
        ensures consistency. A 70/20/10 split (train/validate/test) provides
        robust coverage for model development.
      </p>
      <p>
        Dynamic variables (e.g., NDVI, EVI, precipitation, temperature) and
        static features (e.g., soil/land cover) are ingested in batches via
        efficient queue management, minimizing latency during training.
      </p>
    </div>
  </div>

  <!-- Deep Learning Models -->
  <h2 class="mt-4">Deep Learning Models</h2>
  <div class="card mb-4">
    <div class="card-body">
      <ul>
        <li>
          <strong>Inception-LSTM:</strong> Combines spatial feature extraction
          with LSTM-based temporal modeling.
        </li>
        <li>
          <strong>CNN-Transformers:</strong> Uses a CNN down-sampling path and a
          Transformer encoder for time steps.
        </li>
        <li>
          <strong>Fully Transformer-Based:</strong> Omits convolutional
          operations entirely, focusing on spatiotemporal attention.
        </li>
      </ul>
      <p>
        Multiple iterations (V1–V8) refined hyperparameters (positional
        encodings, attention mechanisms, learning rates, and more). Removing
        batch normalization from most layers helped stabilize training, except
        in squeeze-and-excitation blocks.
      </p>
    </div>
  </div>

  <!-- CNN-Transformer Architecture -->
  <h2 class="mt-4">CNN-Transformer Architecture</h2>
  <div class="card mb-4">
    <div class="card-body">
      <p>
        Our final CNN-Transformer processes inputs of shape [B, T, C, H,
        W]—batch, time steps, channels, height, width. Key elements include:
      </p>
      <ul>
        <li>
          <strong>Down-Sampling Pathway:</strong> Deformable convolutions, SE
          blocks, coordinate attention for hierarchical spatial features.
        </li>
        <li>
          <strong>Transformer Encoder:</strong> Fourier-based positional
          encoding and multi-head attention for temporal modeling.
        </li>
        <li>
          <strong>Up-Sampling Pathway:</strong> Sub-pixel convolution and skip
          connections to restore spatial resolution.
        </li>
      </ul>
      <div class="text-center mt-4">
        <h5>CNN-Transformer Architecture Flow</h5>
        <img
          src="{{ url_for('static', filename='images/CNN-Transformer.png') }}"
          alt="CNN-Transformer Architecture"
          class="img-fluid"
        />
      </div>
    </div>
  </div>

  <!-- Specialized Loss Function -->
  <h2 class="mt-4">Specialized Loss Function</h2>
  <div class="card mb-4">
    <div class="card-body">
      <p>GeoCNN uses a custom loss that evaluates:</p>
      <ul>
        <li>
          <strong>Spatial Dimensions:</strong> Penalizes boundary errors,
          outliers, and no-value regions.
        </li>
        <li>
          <strong>Temporal Dimensions:</strong> Seasonal performance in winter,
          spring, summer, and fall.
        </li>
      </ul>
      <p>
        This ensures that the model captures both local spatial structures and
        broader seasonal trends.
      </p>
    </div>
  </div>
</div>

<style>
  .container {
    max-width: 1200px;
  }

  .card {
    border: none;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  }

  .card-body {
    padding: 2rem;
  }

  .card-title {
    font-size: 1.75rem;
    margin-bottom: 1rem;
  }

  ul {
    font-size: 1.1rem;
    margin-bottom: 1rem;
  }

  .img-fluid {
    border-radius: 10px;
    max-height: 500px;
    object-fit: contain;
  }

  /* Increase size of small prediction vs. ground-truth GIFs */
  .small-gif {
    max-width: 300px;
    height: auto;
  }
</style>

<script>
  const images = Array.from(
    document.querySelectorAll("img[onclick='openModal(this)']")
  );
  const modal = document.getElementById("imageModal");
  const modalImage = document.getElementById("modalImage");
  let currentIndex = 0;

  function openModal(image) {
    currentIndex = images.indexOf(image);
    modalImage.src = image.src;
    modal.style.display = "flex";
    document.addEventListener("keydown", handleKeyDown);
  }

  function closeModal() {
    modal.style.display = "none";
    document.removeEventListener("keydown", handleKeyDown);
  }

  function handleKeyDown(event) {
    if (event.key === "ArrowRight") {
      currentIndex = (currentIndex + 1) % images.length;
    } else if (event.key === "ArrowLeft") {
      currentIndex = (currentIndex - 1 + images.length) % images.length;
    } else if (event.key === "Escape") {
      closeModal();
      return;
    }
    modalImage.src = images[currentIndex].src;
  }
</script>

{% endblock %}
