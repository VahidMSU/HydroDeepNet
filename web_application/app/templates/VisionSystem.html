{% extends "layout.html" %} {% block title %}GeoCNN: Vision System Software{%
endblock %} {% block content %}
<div class="container mt-4">
  <h1 class="mb-4 text-center">GeoCNN: Vision System Software</h1>

  <!-- Introduction Section -->
  <div class="card mb-4">
    <div class="card-body">
      <p class="lead">
        The GeoCNN Vision System is a comprehensive deep learning framework for
        hydrological modeling and prediction. It leverages advanced
        architectures like CNN-Transformers and fully Transformer-based models
        to process large-scale spatiotemporal datasets, enabling robust
        hydrological simulations and insights.
      </p>
    </div>
  </div>

  <!-- Key Components -->
  <h2 class="mt-4">Key Components</h2>

  <!-- Data Pipeline -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">1. Data Pipeline</h3>
      <p>
        The fully integrated data pipeline ensures efficient handling of
        hydrological datasets, including
        <code>SWATCentral.h5</code> and <code>HydroGeoDataset.h5</code>. Its key
        features include:
      </p>
      <ul>
        <li>
          <b>Processing, Loading, Reloading, and Deloading:</b> Handles
          large-scale data with minimal latency.
        </li>
        <li>
          <b>Queue Management:</b> Ensures smooth and continuous data flow
          during training.
        </li>
      </ul>
    </div>
  </div>

  <!-- Deep Learning Models -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">2. Deep Learning Models</h3>
      <p>
        GeoCNN offers state-of-the-art architectures tailored for hydrological
        modeling, including:
      </p>
      <ul>
        <li>
          <b>Inception-LSTM:</b> Combines spatial feature extraction with
          temporal modeling for dynamic hydrological predictions.
        </li>
        <li>
          <b>CNN-Transformers:</b>
          <ul>
            <li>Handles separate static and dynamic data streams.</li>
            <li>Integrates static and dynamic data for robust predictions.</li>
            <li>Enhanced with layer normalization across blocks.</li>
          </ul>
        </li>
        <li>
          <b>Fully Transformer-Based Models:</b> Two highly optimized versions
          designed for spatiotemporal hydrological predictions.
        </li>
      </ul>
    </div>
  </div>

  <!-- Loss Functions -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">3. Specialized Loss Function</h3>
      <p>
        A custom loss function evaluates both spatial and temporal components of
        predictions:
      </p>
      <ul>
        <li>
          <b>Spatial Components:</b>
          <ul>
            <li>Boundary Loss</li>
            <li>Overall Loss</li>
            <li>Torrential Loss</li>
            <li>No-Value Loss</li>
            <li>Outlier Loss</li>
          </ul>
        </li>
        <li>
          <b>Temporal Components:</b>
          <ul>
            <li>Seasonal Losses: Winter, Fall, Spring, Summer</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>

  <!-- Clean Modularization -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">4. Clean Modularization</h3>
      <p>
        The Vision System is fully modularized for clarity and scalability,
        providing:
      </p>
      <ul>
        <li>Flexible hyperparameter configuration.</li>
        <li>Support for training, prediction, and inference setups.</li>
        <li>
          A robust logging system for comprehensive model and pipeline insights.
        </li>
      </ul>
    </div>
  </div>

  <!-- Model Architectures -->
  <h2 class="mt-4">Model Architectures</h2>

  <!-- CNN-Transformers -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">CNN-Transformer Architecture</h3>
      <p>
        Combines convolutional layers for spatial feature extraction with
        Transformers for temporal dependencies. Key components include:
      </p>
      <ul>
        <li>
          <b>Down-Sampling Pathway:</b> Extracts multi-resolution spatial
          features using convolutional layers, SE blocks, and skip connections.
        </li>
        <li>
          <b>Bottleneck Layer:</b> Encodes spatial information into compact
          embeddings for each time step.
        </li>
        <li>
          <b>Temporal Transformer Encoder:</b> Models temporal relationships
          using Fourier positional encoding and multi-head self-attention.
        </li>
        <li>
          <b>Up-Sampling Pathway:</b> Restores spatial resolution with
          deformable convolutions and skip connections.
        </li>
      </ul>
    </div>
  </div>

  <!-- Fully Transformer-Based Models -->
  <div class="card mb-4">
    <div class="card-body">
      <h3 class="card-title">Fully Transformer-Based Models</h3>
      <p>
        Designed for high-resolution spatiotemporal predictions, these models
        replace convolutional operations entirely with attention mechanisms,
        enabling:
      </p>
      <ul>
        <li>Scalability to large datasets.</li>
        <li>Flexibility in adapting to various hydrological tasks.</li>
        <li>Improved performance on long-term temporal predictions.</li>
      </ul>
    </div>
  </div>

  <!-- Visual Representation -->
  <h2 class="mt-4">Visual Representation</h2>
  <div class="text-center">
    <img
      src="{{ url_for('static', filename='images/GeoCNN_Architecture.png') }}"
      class="img-fluid mb-4"
      alt="GeoCNN Architecture Diagram"
    />
  </div>
</div>

<style>
  .container {
    max-width: 1200px;
  }

  .card {
    border: none;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  }

  .card-body {
    padding: 2rem;
  }

  .card-title {
    font-size: 1.75rem;
    margin-bottom: 1rem;
  }

  ul {
    font-size: 1.1rem;
    margin-bottom: 1rem;
  }

  .img-fluid {
    border-radius: 10px;
    max-height: 500px;
    object-fit: contain;
  }
</style>
{% endblock %}
